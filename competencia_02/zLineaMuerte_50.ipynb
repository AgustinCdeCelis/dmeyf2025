{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0cEmzeUKFkPh"
   },
   "source": [
    "# Linea de Muerte Z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DenyKXkiJ5JN"
   },
   "source": [
    "##  1. Big Picture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l-K2_ZsZGrVD"
   },
   "source": [
    "* Preprocesamiento\n",
    "   * Se quitan del datataset los *envenenados* atributos  mprestamos_personales y cprestamos_personales\n",
    "   * Se agregan lags y delta_lags de orden 1 y 2\n",
    "* Modelado no se optimizan hiperarámetros\n",
    "* Produccion\n",
    "   * Entrenamieento final\n",
    "      * Se entrena en {202101, 202102, 202103, 202104}\n",
    "      * Se hace un conservador undersampling de **0.50** de los \"CONTINUA\"\n",
    "      * POS = {\"BAJA+1\", \"BAJA+2\"}\n",
    "      * librería  *zLightGBM*\n",
    "         * **100** canaritos se agregan al comienzo del dataset, porque ahora hay mas datos\n",
    "         * gradient_bound se deja en su default de  **0.1**\n",
    "   * Clasificacion\n",
    "      * Se corta en 11000  envios\n",
    "\n",
    "---\n",
    "Resultados :\n",
    "* ganancia de 391.085 M en el Private Leaderboard ( 11.000 en el Public )\n",
    "* utiliza 17 GB de memoria RAM\n",
    "* corre en 30 minutos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inicializacion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1] \"2025-11-16 17:58:40 UTC\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A matrix: 2 × 6 of type dbl</caption>\n",
       "<thead>\n",
       "\t<tr><th></th><th scope=col>used</th><th scope=col>(Mb)</th><th scope=col>gc trigger</th><th scope=col>(Mb)</th><th scope=col>max used</th><th scope=col>(Mb)</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>Ncells</th><td> 658618</td><td>35.2</td><td>1454660</td><td>77.7</td><td>1189808</td><td>63.6</td></tr>\n",
       "\t<tr><th scope=row>Vcells</th><td>1222364</td><td> 9.4</td><td>8388608</td><td>64.0</td><td>1975153</td><td>15.1</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A matrix: 2 × 6 of type dbl\n",
       "\\begin{tabular}{r|llllll}\n",
       "  & used & (Mb) & gc trigger & (Mb) & max used & (Mb)\\\\\n",
       "\\hline\n",
       "\tNcells &  658618 & 35.2 & 1454660 & 77.7 & 1189808 & 63.6\\\\\n",
       "\tVcells & 1222364 &  9.4 & 8388608 & 64.0 & 1975153 & 15.1\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A matrix: 2 × 6 of type dbl\n",
       "\n",
       "| <!--/--> | used | (Mb) | gc trigger | (Mb) | max used | (Mb) |\n",
       "|---|---|---|---|---|---|---|\n",
       "| Ncells |  658618 | 35.2 | 1454660 | 77.7 | 1189808 | 63.6 |\n",
       "| Vcells | 1222364 |  9.4 | 8388608 | 64.0 | 1975153 | 15.1 |\n",
       "\n"
      ],
      "text/plain": [
       "       used    (Mb) gc trigger (Mb) max used (Mb)\n",
       "Ncells  658618 35.2 1454660    77.7 1189808  63.6\n",
       "Vcells 1222364  9.4 8388608    64.0 1975153  15.1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# limpio la memoria\n",
    "Sys.time()\n",
    "rm(list=ls(all.names=TRUE)) # remove all objects\n",
    "gc(full=TRUE, verbose=FALSE) # garbage collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "PARAM <- list()\n",
    "PARAM$experimento <- \"Definitivo1\"\n",
    "PARAM$semilla_primigenia <- 484643"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "setwd(\"/content/buckets/b1/exp\")\n",
    "experimento_folder <- PARAM$experimento\n",
    "dir.create(experimento_folder, showWarnings=FALSE)\n",
    "setwd( paste0(\"/content/buckets/b1/exp/\", experimento_folder ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocesamiento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dseB4qb9RqUb"
   },
   "source": [
    "### Generacion de la clase_ternaria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "P863YZB9R1Ua"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1] \"2025-11-16 17:58:41 UTC\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading required package: data.table\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A matrix: 2 × 6 of type dbl</caption>\n",
       "<thead>\n",
       "\t<tr><th></th><th scope=col>used</th><th scope=col>(Mb)</th><th scope=col>gc trigger</th><th scope=col>(Mb)</th><th scope=col>max used</th><th scope=col>(Mb)</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>Ncells</th><td>   767462</td><td>  41.0</td><td>   1454660</td><td>  77.7</td><td>  1454660</td><td>  77.7</td></tr>\n",
       "\t<tr><th scope=row>Vcells</th><td>722145172</td><td>5509.6</td><td>1017395732</td><td>7762.2</td><td>845998458</td><td>6454.5</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A matrix: 2 × 6 of type dbl\n",
       "\\begin{tabular}{r|llllll}\n",
       "  & used & (Mb) & gc trigger & (Mb) & max used & (Mb)\\\\\n",
       "\\hline\n",
       "\tNcells &    767462 &   41.0 &    1454660 &   77.7 &   1454660 &   77.7\\\\\n",
       "\tVcells & 722145172 & 5509.6 & 1017395732 & 7762.2 & 845998458 & 6454.5\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A matrix: 2 × 6 of type dbl\n",
       "\n",
       "| <!--/--> | used | (Mb) | gc trigger | (Mb) | max used | (Mb) |\n",
       "|---|---|---|---|---|---|---|\n",
       "| Ncells |    767462 |   41.0 |    1454660 |   77.7 |   1454660 |   77.7 |\n",
       "| Vcells | 722145172 | 5509.6 | 1017395732 | 7762.2 | 845998458 | 6454.5 |\n",
       "\n"
      ],
      "text/plain": [
       "       used      (Mb)   gc trigger (Mb)   max used  (Mb)  \n",
       "Ncells    767462   41.0    1454660   77.7   1454660   77.7\n",
       "Vcells 722145172 5509.6 1017395732 7762.2 845998458 6454.5"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[1] \"2025-11-16 17:59:07 UTC\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Sys.time()\n",
    "require( \"data.table\" )\n",
    "\n",
    "# leo el dataset\n",
    "dataset <- fread(\"~/datasets/competencia_02_crudo.csv.gz\" )\n",
    "\n",
    "# calculo el periodo0 consecutivo\n",
    "dsimple <- dataset[, list(\n",
    "  \"pos\" = .I,\n",
    "  numero_de_cliente,\n",
    "  periodo0 = as.integer(foto_mes/100)*12 +  foto_mes%%100 )\n",
    "]\n",
    "\n",
    "\n",
    "# ordeno\n",
    "setorder( dsimple, numero_de_cliente, periodo0 )\n",
    "\n",
    "# calculo topes\n",
    "periodo_ultimo <- dsimple[, max(periodo0) ]\n",
    "periodo_anteultimo <- periodo_ultimo - 1\n",
    "\n",
    "\n",
    "# calculo los leads de orden 1 y 2\n",
    "dsimple[, c(\"periodo1\", \"periodo2\") :=\n",
    "  shift(periodo0, n=1:2, fill=NA, type=\"lead\"),  numero_de_cliente\n",
    "]\n",
    "\n",
    "# assign most common class values = \"CONTINUA\"\n",
    "dsimple[ periodo0 < periodo_anteultimo, clase_ternaria := \"CONTINUA\" ]\n",
    "\n",
    "# calculo BAJA+1\n",
    "dsimple[ periodo0 < periodo_ultimo &\n",
    "  ( is.na(periodo1) | periodo0 + 1 < periodo1 ),\n",
    "  clase_ternaria := \"BAJA+1\"\n",
    "]\n",
    "\n",
    "# calculo BAJA+2\n",
    "dsimple[ periodo0 < periodo_anteultimo & (periodo0+1 == periodo1 )\n",
    "  & ( is.na(periodo2) | periodo0 + 2 < periodo2 ),\n",
    "  clase_ternaria := \"BAJA+2\"\n",
    "]\n",
    "\n",
    "# pego el resultado en el dataset original y grabo\n",
    "setorder( dsimple, pos )\n",
    "dataset[, clase_ternaria := dsimple$clase_ternaria ]\n",
    "\n",
    "rm(dsimple)\n",
    "gc()\n",
    "Sys.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "meses_a_eliminar <- c(202006, 201910)\n",
    "\n",
    "dataset <- dataset[ !(foto_mes %in% meses_a_eliminar) ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oSKhZRToy2F7"
   },
   "source": [
    "### Eliminacion de Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La auténtica  **salsa mágica**  de este script es la eliminación de estos dos atributos del dataset ya que tran problemas con el Data Drifting\n",
    "* mprestamos_personales\n",
    "* cprestamos_personales\n",
    "\n",
    "el problema con estos campos se detectó manualmente mediante un analisis exploratorio de datos y análisis de corridas de LightGBM en meses previos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1] \"2025-11-16 17:59:08 UTC\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset[, mprestamos_personales := NULL ]\n",
    "dataset[, cprestamos_personales := NULL ]\n",
    "\n",
    "Sys.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineer Intra Mes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1] \"2025-11-16 17:59:09 UTC\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# el mes 1,2, ..12 , podria servir para detectar estacionalidad\n",
    "dataset[, kmes := foto_mes %% 100]\n",
    "\n",
    "# creo un ctr_quarter que tenga en cuenta cuando\n",
    "# los clientes hace 3 menos meses que estan\n",
    "# ya que seria injusto considerar las transacciones medidas en menor tiempo\n",
    "dataset[, ctrx_quarter_normalizado := as.numeric(ctrx_quarter) ]\n",
    "dataset[cliente_antiguedad == 1, ctrx_quarter_normalizado := ctrx_quarter * 5.0]\n",
    "dataset[cliente_antiguedad == 2, ctrx_quarter_normalizado := ctrx_quarter * 2.0]\n",
    "dataset[cliente_antiguedad == 3, ctrx_quarter_normalizado := ctrx_quarter * 1.2]\n",
    "\n",
    "# variable extraida de una tesis de maestria de Irlanda, se perdió el link\n",
    "dataset[, mpayroll_sobre_edad := mpayroll / cliente_edad]\n",
    "\n",
    "Sys.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Engineering Historico"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A partir del dataset crudo, se genera el campo  clase_ternaria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading required package: Rcpp\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if( !require(\"Rcpp\")) install.packages(\"Rcpp\", repos = \"http://cran.us.r-project.org\")\n",
    "require(\"Rcpp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# se calculan para los 6 meses previos el minimo, maximo y\n",
    "#  tendencia calculada con cuadrados minimos\n",
    "# la formula de calculo de la tendencia puede verse en\n",
    "#  https://stats.libretexts.org/Bookshelves/Introductory_Statistics/Book%3A_Introductory_Statistics_(Shafer_and_Zhang)/10%3A_Correlation_and_Regression/10.04%3A_The_Least_Squares_Regression_Line\n",
    "# para la maxíma velocidad esta funcion esta escrita en lenguaje C,\n",
    "# y no en la porqueria de R o Python\n",
    "\n",
    "cppFunction(\"NumericVector fhistC(NumericVector pcolumna, IntegerVector pdesde )\n",
    "{\n",
    "  /* Aqui se cargan los valores para la regresion */\n",
    "  double  x[100] ;\n",
    "  double  y[100] ;\n",
    "\n",
    "  int n = pcolumna.size();\n",
    "  NumericVector out( 5*n );\n",
    "\n",
    "  for(int i = 0; i < n; i++)\n",
    "  {\n",
    "    //lag\n",
    "    if( pdesde[i]-1 < i )  out[ i + 4*n ]  =  pcolumna[i-1] ;\n",
    "    else                   out[ i + 4*n ]  =  NA_REAL ;\n",
    "\n",
    "\n",
    "    int  libre    = 0 ;\n",
    "    int  xvalor   = 1 ;\n",
    "\n",
    "    for( int j= pdesde[i]-1;  j<=i; j++ )\n",
    "    {\n",
    "       double a = pcolumna[j] ;\n",
    "\n",
    "       if( !R_IsNA( a ) )\n",
    "       {\n",
    "          y[ libre ]= a ;\n",
    "          x[ libre ]= xvalor ;\n",
    "          libre++ ;\n",
    "       }\n",
    "\n",
    "       xvalor++ ;\n",
    "    }\n",
    "\n",
    "    /* Si hay al menos dos valores */\n",
    "    if( libre > 1 )\n",
    "    {\n",
    "      double  xsum  = x[0] ;\n",
    "      double  ysum  = y[0] ;\n",
    "      double  xysum = xsum * ysum ;\n",
    "      double  xxsum = xsum * xsum ;\n",
    "      double  vmin  = y[0] ;\n",
    "      double  vmax  = y[0] ;\n",
    "\n",
    "      for( int h=1; h<libre; h++)\n",
    "      {\n",
    "        xsum  += x[h] ;\n",
    "        ysum  += y[h] ;\n",
    "        xysum += x[h]*y[h] ;\n",
    "        xxsum += x[h]*x[h] ;\n",
    "\n",
    "        if( y[h] < vmin )  vmin = y[h] ;\n",
    "        if( y[h] > vmax )  vmax = y[h] ;\n",
    "      }\n",
    "\n",
    "      out[ i ]  =  (libre*xysum - xsum*ysum)/(libre*xxsum -xsum*xsum) ;\n",
    "      out[ i + n ]    =  vmin ;\n",
    "      out[ i + 2*n ]  =  vmax ;\n",
    "      out[ i + 3*n ]  =  ysum / libre ;\n",
    "    }\n",
    "    else\n",
    "    {\n",
    "      out[ i       ]  =  NA_REAL ;\n",
    "      out[ i + n   ]  =  NA_REAL ;\n",
    "      out[ i + 2*n ]  =  NA_REAL ;\n",
    "      out[ i + 3*n ]  =  NA_REAL ;\n",
    "    }\n",
    "  }\n",
    "\n",
    "  return  out;\n",
    "}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calcula la tendencia de las variables cols de los ultimos 6 meses\n",
    "# la tendencia es la pendiente de la recta que ajusta por cuadrados minimos\n",
    "# La funcionalidad de ratioavg es autoria de  Daiana Sparta,  UAustral  2021\n",
    "\n",
    "TendenciaYmuchomas <- function(\n",
    "    dataset, cols, ventana = 6, tendencia = TRUE,\n",
    "    minimo = TRUE, maximo = TRUE, promedio = TRUE,\n",
    "    ratioavg = FALSE, ratiomax = FALSE) {\n",
    "  gc(verbose= FALSE)\n",
    "  # Esta es la cantidad de meses que utilizo para la historia\n",
    "  ventana_regresion <- ventana\n",
    "\n",
    "  last <- nrow(dataset)\n",
    "\n",
    "  # creo el vector_desde que indica cada ventana\n",
    "  # de esta forma se acelera el procesamiento ya que lo hago una sola vez\n",
    "  vector_ids <- dataset[ , numero_de_cliente ]\n",
    "\n",
    "  vector_desde <- seq(\n",
    "    -ventana_regresion + 2,\n",
    "    nrow(dataset) - ventana_regresion + 1\n",
    "  )\n",
    "\n",
    "  vector_desde[1:ventana_regresion] <- 1\n",
    "\n",
    "  for (i in 2:last) {\n",
    "    if (vector_ids[i - 1] != vector_ids[i]) {\n",
    "      vector_desde[i] <- i\n",
    "    }\n",
    "  }\n",
    "  for (i in 2:last) {\n",
    "    if (vector_desde[i] < vector_desde[i - 1]) {\n",
    "      vector_desde[i] <- vector_desde[i - 1]\n",
    "    }\n",
    "  }\n",
    "\n",
    "  for (campo in cols) {\n",
    "    nueva_col <- fhistC(dataset[, get(campo)], vector_desde)\n",
    "\n",
    "    if (tendencia) {\n",
    "      dataset[, paste0(campo, \"_tend\", ventana) :=\n",
    "        nueva_col[(0 * last + 1):(1 * last)]]\n",
    "    }\n",
    "\n",
    "    if (minimo) {\n",
    "      dataset[, paste0(campo, \"_min\", ventana) :=\n",
    "        nueva_col[(1 * last + 1):(2 * last)]]\n",
    "    }\n",
    "\n",
    "    if (maximo) {\n",
    "      dataset[, paste0(campo, \"_max\", ventana) :=\n",
    "        nueva_col[(2 * last + 1):(3 * last)]]\n",
    "    }\n",
    "\n",
    "    if (promedio) {\n",
    "      dataset[, paste0(campo, \"_avg\", ventana) :=\n",
    "        nueva_col[(3 * last + 1):(4 * last)]]\n",
    "    }\n",
    "\n",
    "    if (ratioavg) {\n",
    "      dataset[, paste0(campo, \"_ratioavg\", ventana) :=\n",
    "        get(campo) / nueva_col[(3 * last + 1):(4 * last)]]\n",
    "    }\n",
    "\n",
    "    if (ratiomax) {\n",
    "      dataset[, paste0(campo, \"_ratiomax\", ventana) :=\n",
    "        get(campo) / nueva_col[(2 * last + 1):(3 * last)]]\n",
    "    }\n",
    "  }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Engineering Historico\n",
    "# Creacion de LAGs\n",
    "setorder(dataset, numero_de_cliente, foto_mes)\n",
    "\n",
    "# todo es lagueable, menos la primary key y la clase\n",
    "cols_lagueables <- copy( setdiff(\n",
    "  colnames(dataset),\n",
    "  c(\"numero_de_cliente\", \"foto_mes\", \"clase_ternaria\")\n",
    "))\n",
    "\n",
    "# https://rdrr.io/cran/data.table/man/shift.html\n",
    "\n",
    "# lags de orden 1\n",
    "dataset[,\n",
    "  paste0(cols_lagueables, \"_lag1\") := shift(.SD, 1, NA, \"lag\"),\n",
    "  by= numero_de_cliente,\n",
    "  .SDcols= cols_lagueables\n",
    "]\n",
    "\n",
    "# lags de orden 2\n",
    "dataset[,\n",
    "  paste0(cols_lagueables, \"_lag2\") := shift(.SD, 2, NA, \"lag\"),\n",
    "  by= numero_de_cliente,\n",
    "  .SDcols= cols_lagueables\n",
    "]\n",
    "\n",
    "# agrego los delta lags\n",
    "for (vcol in cols_lagueables)\n",
    "{\n",
    "  dataset[, paste0(vcol, \"_delta1\") := get(vcol) - get(paste0(vcol, \"_lag1\"))]\n",
    "  dataset[, paste0(vcol, \"_delta2\") := get(vcol) - get(paste0(vcol, \"_lag2\"))]\n",
    "}\n",
    "\n",
    "Sys.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parametros de Feature Engineering Historico de Tendencias\n",
    "PARAM$FE_hist$Tendencias$run <- TRUE\n",
    "PARAM$FE_hist$Tendencias$ventana <- 6\n",
    "PARAM$FE_hist$Tendencias$tendencia <- TRUE\n",
    "PARAM$FE_hist$Tendencias$minimo <- TRUE\n",
    "PARAM$FE_hist$Tendencias$maximo <- TRUE\n",
    "PARAM$FE_hist$Tendencias$promedio <- TRUE\n",
    "PARAM$FE_hist$Tendencias$ratioavg <- TRUE\n",
    "PARAM$FE_hist$Tendencias$ratiomax <- TRUE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# aqui se agregan las tendencias de los ultimos 6 meses\n",
    "\n",
    "cols_lagueables <- intersect(cols_lagueables, colnames(dataset))\n",
    "setorder(dataset, numero_de_cliente, foto_mes)\n",
    "\n",
    "if( PARAM$FE_hist$Tendencias$run) {\n",
    "    TendenciaYmuchomas(dataset,\n",
    "    cols = cols_lagueables,\n",
    "    ventana = PARAM$FE_hist$Tendencias$ventana, # 6 meses de historia\n",
    "    tendencia = PARAM$FE_hist$Tendencias$tendencia,\n",
    "    minimo = PARAM$FE_hist$Tendencias$minimo,\n",
    "    maximo = PARAM$FE_hist$Tendencias$maximo,\n",
    "    promedio = PARAM$FE_hist$Tendencias$promedio,\n",
    "    ratioavg = PARAM$FE_hist$Tendencias$ratioavg,\n",
    "    ratiomax = PARAM$FE_hist$Tendencias$ratiomax\n",
    "  )\n",
    "}\n",
    "\n",
    "ncol(dataset)\n",
    "Sys.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelado"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimizacion de Hipeparámetros"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este script no hace optimización de hiperparámetros\n",
    "<br> **No** se llama a una Bayesian Optimization, ese paso se saltea.\n",
    "<br> No hace falta hacer particiones <train, validate, test>,  tampoco se hace un k-fold cross validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xp4-Bj3aYI8d"
   },
   "source": [
    "## Produccion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Las decisiones que se toman para la construccion del modelo final son:\n",
    "* Los positvos son  POS={\"BAJA+1\", \"BAJA+2\"}, esta es una meticulosa decisión.\n",
    "* Se entrena en los cuatro meses  {202101, 202102, 202103, 202104}, esta es una meticulosa decisión.\n",
    "* Se hace un muy consevador undersampling del **0.50** = 50% de la clase mayoritaria (los \"CONTINUA\" )\n",
    "* Obviamente los datos donde se aplica el modelo es el mes  {202106}\n",
    "* Por experimentos en meses anteriores, se decide cortar en los 11000 registros con mayor probabildiad de POS={\"BAJA+1\", \"BAJA+2\"}, , esta es una *enorme* decisión.\n",
    "* No se optmizan los hiperparámetros de LightGBM, sino que se llama a la libreria *zLightGBM*\n",
    "* Para *zLightGBM*  se crean **100** canaritos, esta es una decisión enorme !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training y future\n",
    "Sys.time()\n",
    "\n",
    "PARAM$train_final$meses <- c(201901,201902,201902,201903,201904,201905,\n",
    "                             201906,201907,201908,201909,201911,201912,\n",
    "                             202001,202002,202003,202004,202005,202007,202008,\n",
    "                             202009,202010,202012,202101, 202102, 202103, 202104,202105,202106)\n",
    "PARAM$train_final$undersampling <- 0.05\n",
    "\n",
    "PARAM$future <- c(202108)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kuPfQ7ksjwW3"
   },
   "source": [
    "### Final Training Strategy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se entrena en los cuatro meses {202101, 202102, 202103, 202104}\n",
    "<br>Se hace un conservador undersampling del 50% de la clase mayoritaria (los \"CONTINUA\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# se filtran los meses donde se entrena el modelo final\n",
    "dataset_train_final <- dataset[foto_mes %in% PARAM$train_final$meses]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Registros cambio las proporciones de POS/NEG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Undersampling, van todos los \"BAJA+1\" y \"BAJA+2\" y solo algunos \"CONTINIA\"\n",
    "\n",
    "set.seed(PARAM$semilla_primigenia, kind = \"L'Ecuyer-CMRG\")\n",
    "dataset_train_final[, azar := runif(nrow(dataset_train_final))]\n",
    "dataset_train_final[, training := 0L]\n",
    "\n",
    "dataset_train_final[\n",
    "  (azar <= PARAM$train_final$undersampling | clase_ternaria %in% c(\"BAJA+1\", \"BAJA+2\")),\n",
    "  training := 1L\n",
    "]\n",
    "\n",
    "dataset_train_final[, azar:= NULL] # elimino la columna azar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Target Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# paso la clase a binaria que tome valores {0,1}  enteros\n",
    "#  BAJA+1 y BAJA+2  son  1,   CONTINUA es 0\n",
    "#  a partir de ahora ya NO puedo cortar  por prob(BAJA+2) > 1/40\n",
    "\n",
    "dataset_train_final[,\n",
    "  clase01 := ifelse(clase_ternaria %in% c(\"BAJA+2\",\"BAJA+1\"), 1L, 0L)\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# utilizo  zLightGBM  la nueva libreria\n",
    "if( !require(\"zlightgbm\") ) install.packages(\"https://storage.googleapis.com/open-courses/dmeyf2025-e4a2/zlightgbm_4.6.0.99.tar.gz\", repos= NULL, type= \"source\")\n",
    "require(\"zlightgbm\")\n",
    "Sys.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Un hiperparámetro de  *zLightGBM* es la cantidad de canaritos, en este caso se decidió (con tests realizados en {202101, 202102} fijarlo en 100\n",
    "<br> esta es una importante decisión que debe tomarse\n",
    "<br> en la version actual de *zLightGBM* los canaritos deben agregarse por fuera al dataset, y mandatoriamente deben ser las primeras columnas del mismo\n",
    "<br> durante noviembre, si hay suerte, se liberará una versiónn que lo haga automáticamente internamente en el código C++ de la librería"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# canaritos\n",
    "PARAM$qcanaritos <- 5\n",
    "\n",
    "cols0 <- copy(colnames(dataset_train_final))\n",
    "filas <- nrow(dataset_train_final)\n",
    "\n",
    "for( i in seq(PARAM$qcanaritos) ){\n",
    "  dataset_train_final[, paste0(\"canarito_\",i) := runif( filas) ]\n",
    "}\n",
    "\n",
    "# las columnas canaritos mandatoriamente van al comienzo del dataset\n",
    "cols_canaritos <- copy( setdiff( colnames(dataset_train_final), cols0 ) )\n",
    "setcolorder( dataset_train_final, c( cols_canaritos, cols0 ) )\n",
    "\n",
    "Sys.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xElu4s5W4rX7"
   },
   "outputs": [],
   "source": [
    "# los campos que se van a utilizar\n",
    "\n",
    "campos_buenos <- setdiff(\n",
    "  colnames(dataset_train_final),\n",
    "  c(\"clase_ternaria\", \"clase01\", \"training\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PppMHcGYaaol"
   },
   "outputs": [],
   "source": [
    "# dejo los datos en el formato que necesita LightGBM\n",
    "\n",
    "dtrain_final <- lgb.Dataset(\n",
    "  data= data.matrix(dataset_train_final[training == 1L, campos_buenos, with= FALSE]),\n",
    "  label= dataset_train_final[training == 1L, clase01],\n",
    "  free_raw_data= FALSE\n",
    ")\n",
    "\n",
    "cat(\"filas\", nrow(dtrain_final), \"columnas\", ncol(dtrain_final), \"\\n\")\n",
    "Sys.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nuevos hiperparámetros en  *zLightGBM*\n",
    "* canaritos , entero >=0,  cantidad de atributos del dataset que se consideran como canaritos, mandatoriamente en la version actual deben estar al comienzo.\n",
    "* gradient_bound , numero real, >=0  cota que se pone a los scores de las hojas de los arboles, es un learning_rate adaptativo\n",
    "\n",
    "En el caso que  canaritos==0  y  gradient_bound==0  entonces  xLightGBM se comporta exactamente igual a  LightGBM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tener en cuenta que el hiperparámetro  min_data_in_leaf se está dejando en el valor de 20 que es el default de LightGBM\n",
    "<br> realmente valdria la pena experimentar con distintos valores de  min_data_in_leaf, hay potencial de mejora !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# definicion de parametros, los viejos y los nuevos\n",
    "\n",
    "PARAM$lgbm <-  list(\n",
    "  boosting= \"gbdt\",\n",
    "  objective= \"binary\",\n",
    "  metric= \"custom\",\n",
    "  first_metric_only= FALSE,\n",
    "  boost_from_average= TRUE,\n",
    "  feature_pre_filter= FALSE,\n",
    "  force_row_wise= TRUE,\n",
    "  verbosity= -100,\n",
    "\n",
    "  seed= PARAM$semilla_primigenia,\n",
    "\n",
    "  max_bin= 31L,\n",
    "  min_data_in_leaf= 2000L,  #este ya es el valor default de LightGBM\n",
    "\n",
    "  num_iterations= 9999L, # dejo libre la cantidad de arboles, zLightGBM se detiene solo\n",
    "  num_leaves= 999L, # dejo libre la cantidad de hojas, zLightGBM sabe cuando no hacer un split\n",
    "  learning_rate= 1.0,  # se lo deja en 1.0 para que si el score esta por debajo de gradient_bound no se lo escale\n",
    "    \n",
    "  feature_fraction= 0.50, # un valor equilibrado, habra que probar alternativas ...\n",
    "    \n",
    "  canaritos= PARAM$qcanaritos, # fundamental en zLightGBM, aqui esta el control del overfitting\n",
    "  gradient_bound= 0.01  # default de zLightGBM\n",
    ")\n",
    "\n",
    "Sys.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Entrenamiento del modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aqui se ejecuta  *zLightGBM*\n",
    "<br> no se utilizan hiperparámetros optimos para controlar el overfitting\n",
    "<br> zLightGBM  sabe cuando no hacer un split\n",
    "<br> si al hacer el n-simo arbol, no puede hacer el split de la raiz, detiene el crecimiento del ensemble y termina\n",
    "<br>\n",
    "<br> claramente el  min_data_in_leaf=20 que es el default de LightGBM esta jugando un papel importante"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ssk5nnMk6INK"
   },
   "outputs": [],
   "source": [
    "# entreno el modelo\n",
    "\n",
    "modelo_final <- lgb.train(\n",
    "  data= dtrain_final,\n",
    "  param= PARAM$lgbm\n",
    ")\n",
    "\n",
    "Sys.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grabo el modelo generado, esto pude ser levantado por LighGBM en cualquier maquina\n",
    "lgb.save(modelo_final, file=\"zmodelo.txt\")\n",
    "\n",
    "# grabo un dataset que tiene el detalle de los arboles de LightGBM\n",
    "tb_arboles <- lgb.model.dt.tree(modelo_final)\n",
    "fwrite(tb_arboles, file=\"tb_arboles.txt\", sep=\"\\t\")\n",
    "\n",
    "cat(\"cantidad arbolitos=\", tb_arboles[, max(tree_index)+1],\"\\n\" )\n",
    "cat(\"summary de las hojas de los arboles\")\n",
    "summary( tb_arboles[, list(hojas=max(leaf_index, na.rm=TRUE)+1), tree_index][,hojas])\n",
    "\n",
    "Sys.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfuture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scoring"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se hace el predict() del modelo en los datos del futuro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# aplico el modelo a los datos sin clase\n",
    "dfuture <- dataset[foto_mes %in% PARAM$future]\n",
    "\n",
    "# penosamente, en la versión actual de zLightGBM  los campos canaritos\n",
    "#  aunque no se utilizan para nada, también deben estar en el dataset donde se hace el predict()\n",
    "filas <- nrow(dfuture)\n",
    "\n",
    "for( i in seq(PARAM$qcanaritos) ){\n",
    "  dfuture[, paste0(\"canarito_\",i) := runif( filas) ]\n",
    "}\n",
    "\n",
    "prediccion <- predict(\n",
    "  modelo_final,\n",
    "  data.matrix(dfuture[, campos_buenos, with= FALSE]),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RJwg7LHd11yu"
   },
   "outputs": [],
   "source": [
    "# tabla de prediccion, puede ser util para futuros ensembles\n",
    "#  ya que le modelo ganador va a ser un ensemble de LightGBMs\n",
    "\n",
    "tb_prediccion <- dfuture[, list(numero_de_cliente, foto_mes)]\n",
    "tb_prediccion[, prob := prediccion ]\n",
    "\n",
    "# grabo las probabilidad del modelo\n",
    "fwrite(tb_prediccion,\n",
    "  file= \"prediccion.txt\",\n",
    "  sep= \"\\t\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jOt4eG_55ltv"
   },
   "source": [
    "### Clasificacion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se tomó la decisión de enviar a los 11000 registros con mayor probabilidad de POS={\"BAJA+1\",\"BAJA+\"}\n",
    "<br> esto se determinó en forma artesanal analizando meses anterior\n",
    "<br> esta es una muy importante decisión "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gWW3tatE12je"
   },
   "outputs": [],
   "source": [
    "# genero archivos con los  \"envios\" mejores\n",
    "dir.create(\"kaggle\", showWarnings=FALSE)\n",
    "\n",
    "# ordeno por probabilidad descendente\n",
    "setorder(tb_prediccion, -prob)\n",
    "\n",
    "envios <- 11000\n",
    "tb_prediccion[, Predicted := 0L] # seteo inicial a 0\n",
    "tb_prediccion[1:envios, Predicted := 1L] # marco los primeros\n",
    "\n",
    "archivo_kaggle <- paste0(\"./kaggle/KA\", PARAM$experimento, \"_\", envios, \".csv\")\n",
    "\n",
    "# grabo el archivo\n",
    "fwrite(tb_prediccion[, list(numero_de_cliente, Predicted)],\n",
    "  file= archivo_kaggle,\n",
    "  sep= \",\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clientes_predichos <- tb_prediccion[\n",
    "    Predicted == 1,                          # Condición de fila (i)\n",
    "    list(numero_de_cliente)                  # Columnas a seleccionar (j)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "archivo_kaggle_testeo <- paste0(\"./kaggle/KA_DEF\", PARAM$experimento, \"_\", envios, \".csv\")\n",
    "\n",
    "# grabo el archivo\n",
    "fwrite(clientes_predichos[, list(numero_de_cliente)],\n",
    "  file= archivo_kaggle-testeo,\n",
    "  sep= \",\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Subida a Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9zA_W25c15DP"
   },
   "outputs": [],
   "source": [
    "Sys.time()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
