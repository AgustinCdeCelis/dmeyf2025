{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HNoCqM1I5-le"
   },
   "source": [
    "# Eligiendo modelos con incertidumbre\n",
    "\n",
    "> All models are wrong, but some are useful.\n",
    "\n",
    "George Box\n",
    "\n",
    "> If you torture the data long enough, it will confess.\n",
    "\n",
    "Ronald Coase\n",
    "\n",
    "A esta altura de la maetria, el alumno ya debe saber lo importante que es no sub-ajustar, ni sobre-ajustar un modelo. Puede repasar los conceptos visualmente en el siguiente link http://www.r2d3.us/visual-intro-to-machine-learning-part-2/\n",
    "\n",
    "Para lograr esto, necesitamos \"construir\" el mejor modelo posible. Sin embargo, esto nos plantea dos preguntas clave:\n",
    "* ¿qué significa construir un modelo?\n",
    "* Y, en segundo lugar, si tenemos dos modelos, ¿cómo determinamos cuál es el mejor?\n",
    "\n",
    "Empecemos realizando una comparación entre el modelo por defecto  de **árboles de decisión** (no controla el crecimiento) y uno levemente parametrizado.\n",
    "\n",
    "Levantemos el entorno e instalemos los paquetes que nos probablemente no dispongamos. Se usarán a lo largo de la clase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 14392,
     "status": "ok",
     "timestamp": 1756154423254,
     "user": {
      "displayName": "Joaquín Sebastian Tschopp",
      "userId": "12463161021212811365"
     },
     "user_tz": 180
    },
    "id": "oTlmka0Z7CA5",
    "outputId": "e1e2ac12-6737-4bf1-9e58-b9d7e66d7d7a"
   },
   "outputs": [],
   "source": [
    "%pip install optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 16,
     "status": "ok",
     "timestamp": 1756154423278,
     "user": {
      "displayName": "Joaquín Sebastian Tschopp",
      "userId": "12463161021212811365"
     },
     "user_tz": 180
    },
    "id": "x0IutZ5v4Pn5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/AgustinCepeda/Documents/maestria/datamining_eyf2025/repositorio_materia/dmeyf2025/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree,  _tree\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import ShuffleSplit, StratifiedShuffleSplit\n",
    "\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "from time import time\n",
    "\n",
    "import optuna\n",
    "from optuna.visualization import plot_param_importances, plot_contour,  plot_slice, plot_optimization_history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DgrO4dvN0jCI"
   },
   "source": [
    "Notará a continuación que trabajaremos como mes de entrenamiento **Febrero** y reservaremos **Abril** solo para pruebas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 21322,
     "status": "ok",
     "timestamp": 1756154457370,
     "user": {
      "displayName": "Joaquín Sebastian Tschopp",
      "userId": "12463161021212811365"
     },
     "user_tz": 180
    },
    "id": "IbyPo4Dk4Mdh"
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/content/drive/MyDrive/DMEyF/2024/datos/competencia_01.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 13\u001b[39m\n\u001b[32m     10\u001b[39m \u001b[38;5;66;03m# agregue sus semillas\u001b[39;00m\n\u001b[32m     11\u001b[39m semillas = [\u001b[32m0\u001b[39m, \u001b[32m1\u001b[39m, \u001b[32m2\u001b[39m, \u001b[32m3\u001b[39m, \u001b[32m4\u001b[39m]\n\u001b[32m---> \u001b[39m\u001b[32m13\u001b[39m data = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset_path\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataset_file\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/maestria/datamining_eyf2025/repositorio_materia/dmeyf2025/.venv/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1026\u001b[39m, in \u001b[36mread_csv\u001b[39m\u001b[34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[39m\n\u001b[32m   1013\u001b[39m kwds_defaults = _refine_defaults_read(\n\u001b[32m   1014\u001b[39m     dialect,\n\u001b[32m   1015\u001b[39m     delimiter,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1022\u001b[39m     dtype_backend=dtype_backend,\n\u001b[32m   1023\u001b[39m )\n\u001b[32m   1024\u001b[39m kwds.update(kwds_defaults)\n\u001b[32m-> \u001b[39m\u001b[32m1026\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/maestria/datamining_eyf2025/repositorio_materia/dmeyf2025/.venv/lib/python3.12/site-packages/pandas/io/parsers/readers.py:620\u001b[39m, in \u001b[36m_read\u001b[39m\u001b[34m(filepath_or_buffer, kwds)\u001b[39m\n\u001b[32m    617\u001b[39m _validate_names(kwds.get(\u001b[33m\"\u001b[39m\u001b[33mnames\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[32m    619\u001b[39m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m620\u001b[39m parser = \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    622\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[32m    623\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/maestria/datamining_eyf2025/repositorio_materia/dmeyf2025/.venv/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1620\u001b[39m, in \u001b[36mTextFileReader.__init__\u001b[39m\u001b[34m(self, f, engine, **kwds)\u001b[39m\n\u001b[32m   1617\u001b[39m     \u001b[38;5;28mself\u001b[39m.options[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m] = kwds[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m   1619\u001b[39m \u001b[38;5;28mself\u001b[39m.handles: IOHandles | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1620\u001b[39m \u001b[38;5;28mself\u001b[39m._engine = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/maestria/datamining_eyf2025/repositorio_materia/dmeyf2025/.venv/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1880\u001b[39m, in \u001b[36mTextFileReader._make_engine\u001b[39m\u001b[34m(self, f, engine)\u001b[39m\n\u001b[32m   1878\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[32m   1879\u001b[39m         mode += \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1880\u001b[39m \u001b[38;5;28mself\u001b[39m.handles = \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1881\u001b[39m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1882\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1883\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mencoding\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1884\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcompression\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1885\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmemory_map\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1886\u001b[39m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m=\u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1887\u001b[39m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mencoding_errors\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstrict\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1888\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstorage_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1889\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1890\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m.handles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1891\u001b[39m f = \u001b[38;5;28mself\u001b[39m.handles.handle\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/maestria/datamining_eyf2025/repositorio_materia/dmeyf2025/.venv/lib/python3.12/site-packages/pandas/io/common.py:873\u001b[39m, in \u001b[36mget_handle\u001b[39m\u001b[34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[39m\n\u001b[32m    868\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[32m    869\u001b[39m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[32m    870\u001b[39m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[32m    871\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m ioargs.encoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs.mode:\n\u001b[32m    872\u001b[39m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m873\u001b[39m         handle = \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[32m    874\u001b[39m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    875\u001b[39m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    876\u001b[39m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[43mioargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    877\u001b[39m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    878\u001b[39m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    879\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    880\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    881\u001b[39m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[32m    882\u001b[39m         handle = \u001b[38;5;28mopen\u001b[39m(handle, ioargs.mode)\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: '/content/drive/MyDrive/DMEyF/2024/datos/competencia_01.csv'"
     ]
    }
   ],
   "source": [
    "dataset_path = '/content/drive/MyDrive/DMEyF/2024/datos/'\n",
    "dataset_file = 'competencia_01.csv'\n",
    "\n",
    "ganancia_acierto = 780000\n",
    "costo_estimulo = 20000\n",
    "\n",
    "mes_train = 202102\n",
    "mes_test = 202104\n",
    "\n",
    "# agregue sus semillas\n",
    "semillas = [0, 1, 2, 3, 4]\n",
    "\n",
    "data = pd.read_csv(dataset_path + dataset_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UnYMoA1l4jJ3"
   },
   "outputs": [],
   "source": [
    "X = data[data['foto_mes'] == mes_train]\n",
    "y = X['clase_ternaria']\n",
    "X = X.drop(columns=['clase_ternaria'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "65j320lg1eth"
   },
   "source": [
    "Y necesitamos una función que nos ayude a calcular la ganancia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TWHFFm431krP"
   },
   "outputs": [],
   "source": [
    "def ganancia(model, X, y, prop=1, threshold=0.025):\n",
    "\n",
    "  class_index = np.where(model.classes_ == \"BAJA+2\")[0][0]\n",
    "  y_hat = model.predict_proba(X)\n",
    "\n",
    "  @np.vectorize\n",
    "  def ganancia_row(predicted, actual, threshold=0.025):\n",
    "    return  (predicted >= threshold) * (ganancia_acierto if actual == \"BAJA+2\" else -costo_estimulo)\n",
    "\n",
    "  return ganancia_row(y_hat[:,class_index], y).sum() / prop\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xjQM00zh3FtS"
   },
   "source": [
    "Mira a continuación el siguiente código.\n",
    "\n",
    "* ¿Cuál cree que es el mejor modelo?\n",
    "* ¿Cuáles son los problemas que ve?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 47673,
     "status": "ok",
     "timestamp": 1756152501652,
     "user": {
      "displayName": "Joaquín Sebastian Tschopp",
      "userId": "12463161021212811365"
     },
     "user_tz": 180
    },
    "id": "t_vb-tye2dw_",
    "outputId": "d8e976ee-44c1-4b0d-bb2d-ac967544989d"
   },
   "outputs": [],
   "source": [
    "model_base = DecisionTreeClassifier(random_state=semillas[0])\n",
    "model_ale = DecisionTreeClassifier(criterion='gini',\n",
    "                               random_state=semillas[0],\n",
    "                               min_samples_split=80,\n",
    "                               max_depth=5)\n",
    "\n",
    "model_base.fit(X,y)\n",
    "model_ale.fit(X,y)\n",
    "\n",
    "print(f\"Ganancia de modelo Base: {ganancia(model_base, X, y)}\")\n",
    "print(f\"Ganancia de modelo Ale: {ganancia(model_ale, X, y)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nxS0uXMz3PuY"
   },
   "source": [
    "* ¿Cómo se pueden solucionar?\n",
    "\n",
    "Dado que lo que hicimos no pinta nada bien, pasemos a una de las herramientas que separa la ciencia de datos de la estadística tradicional\n",
    "\n",
    "* ¿Por qué separamos en train/test?\n",
    "* ¿Cómo funciona la estadística tradicional?\n",
    "* Son números aleatorios los que nos dan las computadoras\n",
    "* ¿Por qué usamos semillas?\n",
    "* ¿Qué es una partición estratificada?\n",
    "* ¿Es realmente en nuestro caso una partición estratificada?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "viSb47YW6jIK"
   },
   "source": [
    "Veamos alguna de las formas de separar los conjuntos de datos para medir su calidad:\n",
    "\n",
    "* **Train-Test Split**: Divide el conjunto de datos en dos partes: un conjunto de entrenamiento y otro de prueba. El conjunto de entrenamiento se utiliza para ajustar el modelo, y el conjunto de prueba para evaluar su rendimiento.\n",
    "\n",
    "* **K-Fold Cross Validation**: Divide los datos en k subconjuntos o folds. El modelo se entrena k veces, cada vez utilizando k-1 subconjuntos como entrenamiento y el subconjunto restante como prueba. Esto se repite hasta que cada subconjunto se haya utilizado como conjunto de prueba una vez.\n",
    "\n",
    "* **Shuffle Split** (aka Montecarlo Cross Validation): Genera múltiples particiones aleatorias de los datos en conjuntos de entrenamiento y prueba. A diferencia de K-Fold, no garantiza que todos los puntos de datos sean utilizados en alguna iteración.\n",
    "\n",
    "En la cátedra preferimos usar está última, pero el alumno es libre de usar la que considera conveniente.\n",
    "\n",
    "Armemos ahora nuevamente los modelos anteriores, pero utilizando estas particiones:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3ZGS36pPLM-O"
   },
   "outputs": [],
   "source": [
    "sss = StratifiedShuffleSplit(n_splits=20,\n",
    "                             test_size=0.3,\n",
    "                             random_state=semillas[0])\n",
    "\n",
    "# Función que paraleliza la construcción de árboles de decisión\n",
    "def train_and_evaluate(train_index, test_index, params, X, y):\n",
    "  m = DecisionTreeClassifier(**params)\n",
    "  m.fit(X.iloc[train_index],y.iloc[train_index])\n",
    "  # Note que con el parámetro prop se corrige la distorsión por sampleo de la\n",
    "  # ganancia\n",
    "  ganancia_value = ganancia(m, X.iloc[test_index], y.iloc[test_index], prop=0.3)\n",
    "  return m, ganancia_value\n",
    "\n",
    "modelo_base_param = {\"random_state\":semillas[0]}\n",
    "\n",
    "modelo_ale_param = {\"criterion\": 'gini',\n",
    "                     \"random_state\":semillas[0],\n",
    "                     \"min_samples_split\":80,\n",
    "                     \"max_depth\":5,\n",
    "}\n",
    "\n",
    "results_base = Parallel(n_jobs=-1)(\n",
    "    delayed(train_and_evaluate)(train_index, test_index, modelo_base_param, X, y)\n",
    "    for train_index, test_index in sss.split(X, y)\n",
    ")\n",
    "\n",
    "results_ale = Parallel(n_jobs=-1)(\n",
    "    delayed(train_and_evaluate)(train_index, test_index, modelo_ale_param, X, y)\n",
    "    for train_index, test_index in sss.split(X, y)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ICS3PBYI71h_"
   },
   "source": [
    "Estamos haciendo por cada juego de parámetros 20 modelos. Esto no suele ser lo habitual. Con 5 se puede conseguir buenos resultados.\n",
    "\n",
    "Vamos a ver que tan bien le fue a los modelos en los conjuntos de prueba:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 607
    },
    "executionInfo": {
     "elapsed": 903,
     "status": "ok",
     "timestamp": 1756153312257,
     "user": {
      "displayName": "Joaquín Sebastian Tschopp",
      "userId": "12463161021212811365"
     },
     "user_tz": 180
    },
    "id": "PxNSRwQT8-ZR",
    "outputId": "854556f2-3124-4528-b68c-5ab2e7b90ccc"
   },
   "outputs": [],
   "source": [
    "ganancias_modelos_base = [result[1] for result in results_base]\n",
    "ganancias_modelos_ale = [result[1] for result in results_ale]\n",
    "\n",
    "df_pred = pd.DataFrame({'Ganancia': [result[1] for result in results_base], 'Modelo': 'Base'})\n",
    "df_pred2 = pd.DataFrame({'Ganancia': [result[1] for result in results_ale], 'Modelo': 'Ale'})\n",
    "df_combined = pd.concat([df_pred, df_pred2])\n",
    "\n",
    "g = sns.FacetGrid(df_combined, row=\"Modelo\", aspect=2)\n",
    "g.map(sns.histplot, \"Ganancia\", kde=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dI6se0-A-xsL"
   },
   "source": [
    "* ¿Qué tan distintos son de los primero valores calculados con el modelo completo?\n",
    "* ¿Con cuál se queda?\n",
    "* ¿Por qué se produce semejante dispersión?\n",
    "* ¿Cuál considera que es el \"valor real\"?\n",
    "\n",
    "Podemos mirar la media"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1756153312258,
     "user": {
      "displayName": "Joaquín Sebastian Tschopp",
      "userId": "12463161021212811365"
     },
     "user_tz": 180
    },
    "id": "weA6qiqe-FwA",
    "outputId": "e79f603b-b0fe-40c3-8cbb-29a296e5e8f2"
   },
   "outputs": [],
   "source": [
    "mean_base = df_combined[df_combined['Modelo'] == 'Base']['Ganancia'].mean()\n",
    "mean_ale = df_combined[df_combined['Modelo'] == 'Ale']['Ganancia'].mean()\n",
    "\n",
    "print(f\"Ganancia media del modelo base: {mean_base}\")\n",
    "print(f\"Ganancia media del modelo ale: {mean_ale}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QJatBPAU-67W"
   },
   "source": [
    "* Si no le gusta la media, como más puede elegir un modelo.\n",
    "\n",
    "> **La vida no es simple**  -- Alumno promedio de la maestría.\n",
    "\n",
    "Muy interesante, pero lo importante es que sucedería en el **futuro**. Por este motivo nos guardamos el mes de **Abril**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CjooaKLHXkko"
   },
   "outputs": [],
   "source": [
    "X_futuro = data[data['foto_mes'] == mes_test]\n",
    "y_futuro = X_futuro['clase_ternaria']\n",
    "X_futuro = X_futuro.drop(columns=['clase_ternaria'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BsUTeSfM_goB"
   },
   "source": [
    "Sobre el mes de abril, debemos usar el modelo que se entreno sobre todos los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 367,
     "status": "ok",
     "timestamp": 1756153312748,
     "user": {
      "displayName": "Joaquín Sebastian Tschopp",
      "userId": "12463161021212811365"
     },
     "user_tz": 180
    },
    "id": "h4FixjUZ7owV",
    "outputId": "3b497e5a-4c6f-4993-ee1e-9995a2fb25e0"
   },
   "outputs": [],
   "source": [
    "ganancia_junio_base = ganancia(model_base, X_futuro, y_futuro)\n",
    "ganancia_junio_ale = ganancia(model_ale, X_futuro, y_futuro)\n",
    "\n",
    "print(f\"Ganancia de modelo Base en Junio: {ganancia_junio_base}\")\n",
    "print(f\"Ganancia de modelo Ale en Junio: {ganancia_junio_ale}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UQM8zroBBTjG"
   },
   "source": [
    "* ¿Cuál es mejor?\n",
    "* ¿Por qué cree que el mejor es el mejor?\n",
    "* ¿Hubiera elegido sabiamente únicamente con los datos de **Febrero**?\n",
    "\n",
    "El mundo es un lugar **cruel** para los data scientists. El escenario anterior tampoco es el presente para los alumnos. Ya que **kaggle** divide el dataset en una parte **pública** y otra **privada**. Simulemos los efectos que produce en la decisión del mejor modelo en los leaderboards, simulando varios a la vez.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QoUgUIam8ASR"
   },
   "outputs": [],
   "source": [
    "# podemos tomar más muestras, dado que solo vamos a scorear y eso es más rápido\n",
    "sss_futuro = StratifiedShuffleSplit(n_splits=50,\n",
    "                             test_size=0.3,\n",
    "                             random_state=semillas[0])\n",
    "\n",
    "ganancias_futuro_privada_ale = []\n",
    "ganancias_futuro_privada_base = []\n",
    "ganancias_futuro_publica_ale = []\n",
    "ganancias_futuro_publica_base = []\n",
    "\n",
    "for train_index, test_index in sss_futuro.split(X_futuro, y_futuro):\n",
    "  ganancias_futuro_privada_ale.append(ganancia(model_ale, X_futuro.iloc[train_index], y_futuro.iloc[train_index], prop=0.7))\n",
    "  ganancias_futuro_privada_base.append(ganancia(model_base, X_futuro.iloc[train_index], y_futuro.iloc[train_index], prop=0.7))\n",
    "  ganancias_futuro_publica_ale.append(ganancia(model_ale, X_futuro.iloc[test_index], y_futuro.iloc[test_index], prop=0.3))\n",
    "  ganancias_futuro_publica_base.append(ganancia(model_base, X_futuro.iloc[test_index], y_futuro.iloc[test_index], prop=0.3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 591
    },
    "executionInfo": {
     "elapsed": 1485,
     "status": "ok",
     "timestamp": 1756153352192,
     "user": {
      "displayName": "Joaquín Sebastian Tschopp",
      "userId": "12463161021212811365"
     },
     "user_tz": 180
    },
    "id": "4UTGsLzKE5vQ",
    "outputId": "3570a350-5f47-422a-9caf-34b9bf2a1d29"
   },
   "outputs": [],
   "source": [
    "df_pred_1_ale = pd.DataFrame({'Ganancia': ganancias_futuro_privada_ale, 'Modelo': 'ale', 'Grupo': 'Privado'})\n",
    "df_pred_2_ale = pd.DataFrame({'Ganancia': ganancias_futuro_publica_ale, 'Modelo': 'ale', 'Grupo': 'Publico'})\n",
    "df_pred_1_base = pd.DataFrame({'Ganancia': ganancias_futuro_privada_base, 'Modelo': 'Base', 'Grupo': 'Privado'})\n",
    "df_pred_2_base = pd.DataFrame({'Ganancia': ganancias_futuro_publica_base, 'Modelo': 'Base', 'Grupo': 'Publico'})\n",
    "\n",
    "df_combined = pd.concat([df_pred_1_base, df_pred_2_base, df_pred_1_ale, df_pred_2_ale ])\n",
    "\n",
    "g = sns.FacetGrid(df_combined, col=\"Grupo\", row=\"Modelo\", aspect=2)\n",
    "g.map(sns.histplot, \"Ganancia\", kde=True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 17,
     "status": "ok",
     "timestamp": 1756153352192,
     "user": {
      "displayName": "Joaquín Sebastian Tschopp",
      "userId": "12463161021212811365"
     },
     "user_tz": 180
    },
    "id": "0p7Po1I7FlL6",
    "outputId": "e68566cc-6cdf-46be-e3cf-58c2a2643de4"
   },
   "outputs": [],
   "source": [
    "mean_base_privado = df_combined[(df_combined['Modelo'] == 'Base') & (df_combined['Grupo'] == 'Privado')]['Ganancia'].mean()\n",
    "mean_base_publico = df_combined[(df_combined['Modelo'] == 'Base') & (df_combined['Grupo'] == 'Publico')]['Ganancia'].mean()\n",
    "mean_ale_privado = df_combined[(df_combined['Modelo'] == 'ale') & (df_combined['Grupo'] == 'Privado')]['Ganancia'].mean()\n",
    "mean_ale_publico = df_combined[(df_combined['Modelo'] == 'ale') & (df_combined['Grupo'] == 'Publico')]['Ganancia'].mean()\n",
    "\n",
    "print(f\"Ganancia media del modelo base en privado: {mean_base_privado}\")\n",
    "print(f\"Ganancia media del modelo base en publico: {mean_base_publico}\")\n",
    "print(f\"Ganancia media del modelo ale en privado: {mean_ale_privado}\")\n",
    "print(f\"Ganancia media del modelo ale en publico: {mean_ale_publico}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gw0NeIfOG77K"
   },
   "source": [
    "* ¿Que significa todo esto?\n",
    "\n",
    "Bueno, dos cosas.\n",
    "\n",
    "* El modelo ale, es un caso de **vagancia**. Cambiar 2 parámetros y esperar un cambio radical no es lo más inteligente que se puede hacer. Realmente hay que hacer un esfuerzo para separar las distribuciones.\n",
    "* Aún así elegir un modelo no es una tarea simple que se pueda hacer con una **certeza** absoluta.\n",
    "\n",
    "Para mejorar los modelos, una paso adecuado es la búsqueda de hiperparámetros. Podemos contar con las siguientes técnicas de búsqueda de parámetros:\n",
    "\n",
    "* **Grid Search**: Explora exhaustivamente todas las combinaciones posibles de hiperparámetros dentro de un conjunto predefinido de valores. Aunque es exhaustivo.\n",
    "\n",
    "* **Random Search**: En lugar de probar todas las combinaciones posibles, selecciona un número aleatorio de combinaciones de hiperparámetros dentro de un rango predefinido.\n",
    "\n",
    "* **Bayesian Optimization**: Este método construye un modelo probabilístico del rendimiento de los hiperparámetros y utiliza ese modelo para seleccionar los valores de hiperparámetros más prometedores.\n",
    "\n",
    "* **Tree-structured Parzen Estimator (TPE)**: Una variante de la optimización bayesiana que utiliza estimadores de densidad basados en árboles (Parzen estimators) para modelar la probabilidad de los hiperparámetros óptimos. Es eficiente en la exploración de espacios de hiperparámetros complejos y se adapta bien a configuraciones con interdependencias entre los parámetros.\n",
    "\n",
    "* **Genetic Algorithms**: Emplea principios de la evolución natural, como selección, cruce y mutación, para encontrar combinaciones óptimas de hiperparámetros. Es útil en espacios de búsqueda complejos, aunque puede ser computacionalmente costoso.\n",
    "\n",
    "Repasemos en clase de que se trata cada uno. (tome notas)\n",
    "\n",
    "Todos nos buenas opciones para la búsqueda de ... nah mentira, **grid search** apesta, si no me cree calcule el tiempo necesario para barrer el dominio de búsqueda.\n",
    "\n",
    "Para la búsquedas de parámetros usaremos **Optuna**. **Optuna** es una librería poderosa y flexible, diseñada para realizar búsquedas eficientes y automatizadas.\n",
    "\n",
    "* Utiliza casi todos los álgoritmos mencionados y más.\n",
    "\n",
    "* Permite definir espacios de búsqueda complejos, incluyendo hiperparámetros categóricos, continuos, discretos y con dependencias condicionales.\n",
    "\n",
    "* Ofrece un mecanismo de pruning o poda, que permite detener evaluaciones de configuraciones de hiperparámetros que no muestran promesas tempranas.\n",
    "\n",
    "* Facilidad de Uso y Configuración.\n",
    "\n",
    "* Proporciona herramientas de visualización integradas para analizar el progreso de la optimización, visualizar la importancia de los hiperparámetros y explorar las configuraciones probadas.\n",
    "\n",
    "Buscaremos un mejor modelo de manera inteligente:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1070,
     "status": "ok",
     "timestamp": 1756154485445,
     "user": {
      "displayName": "Joaquín Sebastian Tschopp",
      "userId": "12463161021212811365"
     },
     "user_tz": 180
    },
    "id": "85WbW6qroyfn",
    "outputId": "2277d434-f4cf-49f7-8f94-2ae30819a5ff"
   },
   "outputs": [],
   "source": [
    "\n",
    "sss_opt = ShuffleSplit(n_splits=5, test_size=0.3, random_state=semillas[1])\n",
    "\n",
    "def objective(trial, X, y, sss):\n",
    "  criterion = trial.suggest_categorical('criterion', ['gini', 'entropy'])\n",
    "  max_depth = trial.suggest_int('max_depth', 2, 20)\n",
    "  min_samples_split = trial.suggest_int('min_samples_split', 2, 200)\n",
    "  min_samples_leaf = trial.suggest_int('min_samples_leaf', 1, 20)\n",
    "  max_leaf_nodes = trial.suggest_int('max_leaf_nodes', 2, 20)\n",
    "\n",
    "  def train_and_evaluate(train_index, test_index, X, y):\n",
    "    m = DecisionTreeClassifier(\n",
    "        criterion=criterion,\n",
    "        max_depth=max_depth,\n",
    "        min_samples_split=min_samples_split,\n",
    "        min_samples_leaf=min_samples_leaf,\n",
    "        max_leaf_nodes=max_leaf_nodes,\n",
    "        random_state=semillas[0],\n",
    "    )\n",
    "    m.fit(X.iloc[train_index],y.iloc[train_index])\n",
    "    ganancia_value = ganancia(m, X.iloc[test_index], y.iloc[test_index], prop=0.3)\n",
    "    return ganancia_value\n",
    "\n",
    "  results = Parallel(n_jobs=-1)(\n",
    "      delayed(train_and_evaluate)(train_index, test_index, X, y)\n",
    "      for train_index, test_index in sss.split(X)\n",
    "  )\n",
    "\n",
    "  return np.mean(results)\n",
    "\n",
    "storage_name = \"sqlite:////content/drive/MyDrive/Datos/optimization_tree.db\"\n",
    "study_name = \"exp_101_decision-tree-opt\"\n",
    "\n",
    "study = optuna.create_study(\n",
    "    direction=\"maximize\",\n",
    "    study_name=study_name,\n",
    "    storage=storage_name,\n",
    "    load_if_exists=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1pLQD79dbP9P"
   },
   "source": [
    "Entre la muchas ventajas que tiene **Optuna** es que va almacenando las exploraciones en una base de datos, lo que nos permite continuar la búsqueda si esta se interrumpe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2656571,
     "status": "ok",
     "timestamp": 1756157165375,
     "user": {
      "displayName": "Joaquín Sebastian Tschopp",
      "userId": "12463161021212811365"
     },
     "user_tz": 180
    },
    "id": "Ba56plD9bLup",
    "outputId": "1397baa5-de08-468b-b2f8-f21c3ea4898f"
   },
   "outputs": [],
   "source": [
    "# No quiero que se ejecute automaticamente\n",
    "study.optimize(lambda trial: objective(trial, X, y, sss_opt), n_trials=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KM8WsVYMcE6M"
   },
   "source": [
    "A continuación veremos como fue el proceso de búsqueda a través de las visualizaciones que cuenta la herramienta (los gráficos son bastante autoexplicativos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 542
    },
    "executionInfo": {
     "elapsed": 485,
     "status": "ok",
     "timestamp": 1756157165859,
     "user": {
      "displayName": "Joaquín Sebastian Tschopp",
      "userId": "12463161021212811365"
     },
     "user_tz": 180
    },
    "id": "wJ9-4XqG64AD",
    "outputId": "670ed9ca-6f61-4d1a-95b9-53c36985a7e0"
   },
   "outputs": [],
   "source": [
    "optuna.visualization.plot_optimization_history(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 542
    },
    "executionInfo": {
     "elapsed": 703,
     "status": "ok",
     "timestamp": 1756157166571,
     "user": {
      "displayName": "Joaquín Sebastian Tschopp",
      "userId": "12463161021212811365"
     },
     "user_tz": 180
    },
    "id": "C4o1mz-b53_Q",
    "outputId": "fc2c73da-8394-4be6-f4b4-81b857b3f016"
   },
   "outputs": [],
   "source": [
    "plot_param_importances(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 542
    },
    "executionInfo": {
     "elapsed": 361,
     "status": "ok",
     "timestamp": 1756157166933,
     "user": {
      "displayName": "Joaquín Sebastian Tschopp",
      "userId": "12463161021212811365"
     },
     "user_tz": 180
    },
    "id": "XhcFEzRB62J2",
    "outputId": "acf83e4a-68d0-4c5c-f885-182e1afe57a0"
   },
   "outputs": [],
   "source": [
    "plot_slice(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 542
    },
    "executionInfo": {
     "elapsed": 636,
     "status": "ok",
     "timestamp": 1756157167575,
     "user": {
      "displayName": "Joaquín Sebastian Tschopp",
      "userId": "12463161021212811365"
     },
     "user_tz": 180
    },
    "id": "ZXGkSPR46pzy",
    "outputId": "d13a8015-1cd6-4037-bf25-0bc1403a44ae"
   },
   "outputs": [],
   "source": [
    "plot_contour(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 542
    },
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1756157167587,
     "user": {
      "displayName": "Joaquín Sebastian Tschopp",
      "userId": "12463161021212811365"
     },
     "user_tz": 180
    },
    "id": "KIu_VjPn-LrW",
    "outputId": "d4e450cf-bc47-420d-dd0d-b3299e709404"
   },
   "outputs": [],
   "source": [
    "plot_contour(study, params=[\"max_depth\", \"max_leaf_nodes\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tYy1gCarctOm"
   },
   "source": [
    "Pasemos a analizar como le fue al mejor modelo en **Abril**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10572,
     "status": "ok",
     "timestamp": 1756157178159,
     "user": {
      "displayName": "Joaquín Sebastian Tschopp",
      "userId": "12463161021212811365"
     },
     "user_tz": 180
    },
    "id": "qX8GEf5M7aH1",
    "outputId": "98873d24-c3e7-442a-915c-3d3f6f9730ad"
   },
   "outputs": [],
   "source": [
    "# Obtener el mejor modelo\n",
    "best_trial = study.best_trial\n",
    "best_model_params = best_trial.params\n",
    "print(\"Mejor modelo:\", best_model_params)\n",
    "\n",
    "model_best = DecisionTreeClassifier(**best_model_params, random_state=semillas[0])\n",
    "model_best.fit(X, y)\n",
    "\n",
    "print(f\"Ganancia del mejor modelo: {ganancia(model_best, X_futuro, y_futuro)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9yK8LBJVeD8R"
   },
   "source": [
    "Es mejor que los anteriores! y solo por una hora de procesamiento!!!\n",
    "\n",
    "¿qué más podemos pedir por tan poco?\n",
    "\n",
    "Veamos comparados con los anteriores que tanto mejor es...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 907
    },
    "executionInfo": {
     "elapsed": 22382,
     "status": "ok",
     "timestamp": 1756157200544,
     "user": {
      "displayName": "Joaquín Sebastian Tschopp",
      "userId": "12463161021212811365"
     },
     "user_tz": 180
    },
    "id": "kRWjXvFWTTdL",
    "outputId": "d55c55a0-58a8-4ebd-c218-b76484b5cb82"
   },
   "outputs": [],
   "source": [
    "ganancias_futuro_top0_publica = []\n",
    "ganancias_futuro_top0_privado = []\n",
    "for train_index, test_index in sss_futuro.split(X_futuro, y_futuro):\n",
    "  ganancias_futuro_top0_publica.append(ganancia(model_best, X_futuro.iloc[test_index], y_futuro.iloc[test_index], prop=0.3))\n",
    "  ganancias_futuro_top0_privado.append(ganancia(model_best, X_futuro.iloc[train_index], y_futuro.iloc[train_index], prop=0.7))\n",
    "\n",
    "df_pred_top0_privado = pd.DataFrame({'Ganancia': ganancias_futuro_top0_privado, 'Modelo': 'top0', 'Grupo': 'Privado'})\n",
    "df_pred_top0_publica = pd.DataFrame({'Ganancia': ganancias_futuro_top0_publica, 'Modelo': 'top0', 'Grupo': 'Publico'})\n",
    "\n",
    "df_combined = pd.concat([df_pred_1_base,\n",
    "                         df_pred_2_base,\n",
    "                         df_pred_1_ale,\n",
    "                         df_pred_2_ale,\n",
    "                         df_pred_top0_privado,\n",
    "                         df_pred_top0_publica])\n",
    "\n",
    "g = sns.FacetGrid(df_combined, col=\"Grupo\", row=\"Modelo\", aspect=2)\n",
    "g.map(sns.histplot, \"Ganancia\", kde=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "djfNrxaXeaMa"
   },
   "source": [
    "Bueno, no parece mucho mejor. Es tan solo mejor. Vamos moviendo de a poco la vara.\n",
    "\n",
    "* ¿Qué se puede hacer para mejorarlo? Debate con la clase abierta\n",
    "\n",
    "Una última cosa, solo de pura maldad..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 28500,
     "status": "ok",
     "timestamp": 1756157229043,
     "user": {
      "displayName": "Joaquín Sebastian Tschopp",
      "userId": "12463161021212811365"
     },
     "user_tz": 180
    },
    "id": "jZ7r-UOgSw58",
    "outputId": "d04f26d1-03c4-4e2f-cb2a-a7731d3deebf"
   },
   "outputs": [],
   "source": [
    "n_top_models = 3\n",
    "top_trials = study.best_trials[0:n_top_models]\n",
    "\n",
    "top_models = []\n",
    "for i, trial in enumerate(top_trials):\n",
    "     model_params = trial.params\n",
    "     print(f\"Top {i}: {model_params}\")\n",
    "     model = DecisionTreeClassifier(**model_params, random_state=semillas[0])\n",
    "     model.fit(X, y)\n",
    "     top_models.append(model)\n",
    "\n",
    "ganancias_abril = []\n",
    "for model in top_models:\n",
    "  ganancias_abril.append(ganancia(model, X_futuro, y_futuro))\n",
    "\n",
    "for i, ganancia_abril in enumerate(ganancias_abril):\n",
    "  print(f\"Ganancia de top {i} en abril: {ganancia_abril}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Gk_3Fuly0vmI"
   },
   "source": [
    "## Tarea:\n",
    "\n",
    "* Envíos a Kaggle:\n",
    " * Defina los mejores parámetros para realizar una búsqueda.\n",
    " * Explore la configuración de Optuna para una mejor búsqueda.\n",
    " * Arme un script que tome la salida de un modelo y genere un archivo para Kaggle.\n",
    " * Entrena el modelo usando datos de febrero y mirando su rendimiento en abril.  \n",
    "   * Prueba el modelo completo entrenado en febrero, score en Junio y suba a  Kaggle.\n",
    "   * El modelo seleccionado se reentrena con los datos de abril y se scorea en junio para kaggle\n",
    "* Busca el mejor modelo en abril y scoree en junio para Kaggle.\n",
    "\n",
    "¿Cuál fue su mejor predicción?\n",
    "\n",
    "Colaboración:\n",
    "* Recuerde compartir con tus compañeros los nuevos scripts que hayas generado y las configuraciones que hayas probado por el canal de"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
